<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Product Workflow Generator - AI Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: #f5f5f5;
            margin: 0;
            padding: 0;
            height: 100vh;
            overflow: hidden;
        }

        .main-container {
            display: flex;
            height: 100vh;
            gap: 0;
            flex-direction: row;
        }

        @media (max-width: 768px) {
            .main-container {
                flex-direction: column;
                height: auto;
                min-height: 100vh;
            }
            
            .editor-panel {
                border-right: none;
                border-bottom: 2px solid #e0e0e0;
                min-height: 400px;
            }
        }

        .editor-panel {
            flex: 1;
            background: white;
            border-right: 2px solid #e0e0e0;
            display: flex;
            flex-direction: column;
            overflow: hidden;
            min-width: 0;
        }

        .editor-header {
            padding: 20px;
            background: #f8f9fa;
            border-bottom: 1px solid #e0e0e0;
        }

        .editor-header h2 {
            margin: 0;
            color: #333;
            font-size: 20px;
        }

        .diagram-container {
            flex: 1;
            padding: 20px;
            overflow: auto;
            background: white;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .diagram-container.empty {
            color: #999;
            font-size: 16px;
        }

        .chat-panel {
            flex: 1;
            background: white;
            display: flex;
            flex-direction: column;
            overflow: hidden;
            min-width: 0;
        }

        @media (max-width: 768px) {
            .chat-panel {
                min-height: 500px;
            }
        }

        .chat-header {
            padding: 15px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .chat-header h2 {
            margin: 0;
            font-size: 18px;
        }

        @media (max-width: 768px) {
            .chat-header {
                padding: 12px 15px;
            }
            
            .chat-header h2 {
                font-size: 16px;
            }
        }

        .container {
            flex: 1;
            display: flex;
            flex-direction: column;
            padding: 15px;
            overflow: hidden;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 20px;
            font-size: 24px;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .call-button {
            width: 100%;
            padding: 20px;
            font-size: 20px;
            font-weight: bold;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 12px;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            margin-bottom: 20px;
        }

        .call-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.4);
        }

        .call-button:active {
            transform: translateY(0);
        }

        .call-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .status {
            text-align: center;
            padding: 15px;
            margin-bottom: 20px;
            border-radius: 8px;
            font-weight: bold;
        }

        .status.idle {
            background: #e3f2fd;
            color: #1976d2;
        }

        .status.listening {
            background: #fff3e0;
            color: #f57c00;
        }

        .status.processing {
            background: #f3e5f5;
            color: #7b1fa2;
        }


        .conversation {
            flex: 1;
            overflow-y: auto;
            margin-bottom: 15px;
            padding: 15px;
            background: #f5f5f5;
            border-radius: 12px;
        }

        .text-input-container {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
        }

        .text-input {
            flex: 1;
            padding: 12px 15px;
            border: 2px solid #ddd;
            border-radius: 25px;
            font-size: 16px;
            font-family: inherit;
            outline: none;
            transition: border-color 0.3s;
        }

        .text-input:focus {
            border-color: #667eea;
        }

        .send-button {
            padding: 12px 25px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            transition: transform 0.2s;
        }

        .send-button:hover {
            transform: scale(1.05);
        }

        .send-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .mermaid-container {
            margin: 15px 0;
            padding: 15px;
            background: white;
            border-radius: 8px;
            border: 2px solid #667eea;
            text-align: center;
        }

        .download-button {
            margin-top: 10px;
            padding: 10px 20px;
            background: #4caf50;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 14px;
            font-weight: bold;
            cursor: pointer;
            transition: background 0.3s;
        }

        .download-button:hover {
            background: #45a049;
        }

        .voice-button {
            padding: 12px 20px;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            transition: transform 0.2s;
            margin-bottom: 15px;
        }

        .voice-button:hover {
            transform: scale(1.05);
        }

        .voice-button.recording {
            background: #f5576c;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
            animation: fadeIn 0.3s;
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            background: #667eea;
            color: white;
            text-align: left;
            margin-right: 20%;
        }

        .message.fahd {
            background: #764ba2;
            color: white;
            text-align: right;
            margin-left: 20%;
        }


        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top-color: white;
            animation: spin 1s ease-in-out infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .status.error {
            background: #ffebee;
            color: #c62828;
            font-size: 18px;
            padding: 20px;
            border: 2px solid #c62828;
        }
    </style>
</head>
<body>
    <div class="main-container">
        <!-- Left Panel: Editor for Diagrams -->
        <div class="editor-panel">
            <div class="editor-header">
                <h2>ðŸ“Š Workflow Diagram</h2>
            </div>
            <div id="diagramContainer" class="diagram-container empty">
                <div>No diagram generated yet. Describe your workflow to generate a diagram.</div>
            </div>
        </div>

        <!-- Right Panel: Chatbot -->
        <div class="chat-panel">
            <div class="chat-header">
                <h2>ðŸ’¬ AI Assistant</h2>
            </div>
            <div class="container">
                <div class="text-input-container">
                    <input type="text" id="textInput" class="text-input" placeholder="Type your message or describe your workflow..." />
                    <button id="sendButton" class="send-button">Send</button>
                </div>

                <button id="voiceButton" class="voice-button">ðŸŽ¤ Record Voice</button>
                
                <div id="status" class="status idle">Ready</div>
                
                <div id="conversation" class="conversation"></div>
            </div>
        </div>
    </div>

    <!-- Mermaid.js library -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>

    <script>
        const GROQ_API_KEY = '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';
        const GROQ_API_URL = 'https://api.groq.com/openai/v1';

        let isCalling = false;
        let mediaRecorder = null;
        let audioChunks = [];
        let microphoneStream = null;
        let silenceTimer = null;
        let audioContext = null;
        let analyser = null;
        let silenceThreshold = 0.01;
        let lastSoundTime = Date.now();
        let conversationHistory = [];

        // callButton removed - using text input and voice button instead
        const statusDiv = document.getElementById('status');
        const conversationDiv = document.getElementById('conversation');
        const diagramContainer = document.getElementById('diagramContainer');

        // System prompt for Product Management Assistant
        const SYSTEM_PROMPT = `You are an AI Product Management Assistant specialized in creating workflow diagrams for sprint planning and business processes.

CRITICAL RULES - READ CAREFULLY:
1. When the user describes a workflow, process, or sprint plan, you MUST respond with ONLY the Mermaid code block
2. DO NOT add any text before or after the Mermaid code
3. DO NOT add explanations or descriptions
4. Your response MUST start with \`\`\`mermaid and end with \`\`\`
5. The ONLY thing in your response should be the Mermaid code block

Response format (ONLY this, nothing else):
\`\`\`mermaid
graph TD
    A[Start] --> B[Task 1]
    B --> C[Task 2]
    C --> D[End]
\`\`\`

Important:
- Use flowcharts (graph TD) for process flows
- Use sequence diagrams for interactions
- Use Gantt charts for timelines
- Make sure the Mermaid syntax is correct and complete
- If the user asks about something unrelated to workflows, respond with: "Please describe a workflow or process to generate a diagram."`;


        // Speech to Text using Groq Whisper
        async function speechToText(audioBlob) {
            try {
                const formData = new FormData();
                formData.append('file', audioBlob, 'audio.webm');
                formData.append('model', 'whisper-large-v3');
                formData.append('language', 'ar');

                const response = await fetch(`${GROQ_API_URL}/audio/transcriptions`, {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${GROQ_API_KEY}`
                    },
                    body: formData
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    console.error('STT Error:', response.status, errorText);
                    if (response.status === 401) {
                        throw new Error('401 Unauthorized: Invalid API key. Please check your Groq API key.');
                    }
                    throw new Error(`Speech to text failed: ${response.status} - ${errorText}`);
                }

                const data = await response.json();
                return data.text || '';
            } catch (error) {
                console.error('Speech to text error:', error);
                throw error;
            }
        }

        // Text processing using Groq GPT
        async function processText(userMessage) {
            try {
                // Build messages array with system prompt, conversation history, and current message
                // conversationHistory already contains all previous messages (user and assistant)
                const messages = [
                    {
                        role: 'system',
                        content: SYSTEM_PROMPT
                    },
                    ...conversationHistory, // All previous conversation history
                    {
                        role: 'user',
                        content: userMessage
                    }
                ];
                
                // Try the specified model first, fallback to available models
                const models = ['openai/gpt-oss-120b', 'llama-3.1-70b-versatile', 'mixtral-8x7b-32768'];
                
                for (const model of models) {
                    try {
                        const response = await fetch(`${GROQ_API_URL}/chat/completions`, {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                                'Authorization': `Bearer ${GROQ_API_KEY}`
                            },
                            body: JSON.stringify({
                                model: model,
                                messages: messages,
                                temperature: 0.7,
                                max_tokens: 500
                            })
                        });

                        if (response.ok) {
                            const data = await response.json();
                            let content = data.choices[0].message.content;
                            
                            // If content is empty, try to extract Mermaid code from reasoning
                            if (!content || content.trim() === '') {
                                console.log('Content is empty, checking reasoning field...');
                                if (data.choices[0].message.reasoning) {
                                    const reasoning = data.choices[0].message.reasoning;
                                    console.log('Reasoning content:', reasoning);
                                    
                                    // Try to extract Mermaid code from reasoning
                                    const mermaidMatch = reasoning.match(/```\s*mermaid\s*([\s\S]*?)```/i);
                                    if (mermaidMatch) {
                                        // Return just the mermaid code block
                                        content = '```mermaid\n' + mermaidMatch[1].trim() + '\n```';
                                        console.log('Extracted Mermaid from reasoning:', content);
                                    } else {
                                        // If no code block, use reasoning as is
                                        content = reasoning;
                                    }
                                }
                            }
                            
                            return content || '';
                        } else {
                            const errorData = await response.text();
                            console.error(`Model ${model} failed:`, response.status, errorData);
                            if (response.status === 401) {
                                throw new Error(`Authentication failed. Please check your API key. Status: ${response.status}`);
                            }
                        }
                    } catch (e) {
                        console.log(`Model ${model} error:`, e.message);
                        if (e.message.includes('Authentication failed')) {
                            throw e; // Re-throw auth errors immediately
                        }
                        continue;
                    }
                }
                
                throw new Error('All models failed. Please check your API key and try again.');
            } catch (error) {
                console.error('Text processing error:', error);
                // Fallback response
                return 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©ØŸ';
            }
        }

        // TTS removed - AI will not talk

        // Add message to conversation
        // Extract Mermaid code from text (simplified - expects only mermaid code block)
        function extractMermaidCode(text) {
            if (!text) return [];
            
            // Simple pattern: extract everything between ```mermaid and ```
            const pattern = /```\s*mermaid\s*([\s\S]*?)```/gi;
            const matches = [];
            let match;
            
            while ((match = pattern.exec(text)) !== null) {
                const code = match[1].trim();
                if (code && code.length > 5) {
                    matches.push(code);
                }
            }
            
            // If no code block found but text contains "graph", try to extract it
            if (matches.length === 0 && text.includes('graph')) {
                const graphMatch = text.match(/graph\s+[TDLR|TB]+\s+([\s\S]*)/i);
                if (graphMatch) {
                    const fullGraph = text.match(/(graph\s+[TDLR|TB]+\s+[\s\S]*)/i);
                    if (fullGraph && fullGraph[0].trim().length > 10) {
                        matches.push(fullGraph[0].trim());
                    }
                }
            }
            
            console.log('Extracted Mermaid codes:', matches);
            return matches;
        }

        // Render Mermaid diagram in left editor panel
        async function renderMermaidDiagram(mermaidCode) {
            try {
                const diagramContainer = document.getElementById('diagramContainer');
                if (!diagramContainer) {
                    console.error('Diagram container not found');
                    return false;
                }
                
                diagramContainer.classList.remove('empty');
                diagramContainer.innerHTML = ''; // Clear previous diagram
                
                const diagramId = `diagram-${Date.now()}`;
                const { svg } = await mermaid.render(diagramId, mermaidCode);
                
                const svgDiv = document.createElement('div');
                svgDiv.innerHTML = svg;
                svgDiv.style.width = '100%';
                svgDiv.style.display = 'flex';
                svgDiv.style.justifyContent = 'center';
                svgDiv.style.alignItems = 'center';
                
                // Add download button (PNG only)
                const downloadBtn = document.createElement('button');
                downloadBtn.className = 'download-button';
                downloadBtn.textContent = 'ðŸ“¥ Download PNG';
                downloadBtn.style.marginTop = '20px';
                downloadBtn.onclick = () => {
                    const svgElement = svgDiv.querySelector('svg');
                    if (svgElement) {
                        downloadDiagram(svgElement, `workflow-${Date.now()}`);
                    }
                };
                
                const wrapper = document.createElement('div');
                wrapper.style.textAlign = 'center';
                wrapper.style.width = '100%';
                wrapper.appendChild(svgDiv);
                wrapper.appendChild(downloadBtn);
                
                diagramContainer.appendChild(wrapper);
                return true;
            } catch (error) {
                console.error('Mermaid rendering error:', error);
                const diagramContainer = document.getElementById('diagramContainer');
                if (diagramContainer) {
                    diagramContainer.innerHTML = `<div style="color: red; padding: 20px;">Error rendering diagram: ${error.message}</div>`;
                }
                return false;
            }
        }

        // Download diagram as PNG
        async function downloadDiagram(svgElement, filename = 'workflow-diagram') {
            try {
                // Get SVG as string
                const svgData = new XMLSerializer().serializeToString(svgElement);
                
                // Get viewBox or dimensions from SVG
                const viewBox = svgElement.getAttribute('viewBox');
                let width, height;
                
                if (viewBox) {
                    const parts = viewBox.split(/\s+/);
                    width = parseFloat(parts[2]) || 1200;
                    height = parseFloat(parts[3]) || 800;
                } else {
                    width = svgElement.width?.baseVal?.value || 
                            parseFloat(svgElement.getAttribute('width')) || 
                            svgElement.getBoundingClientRect().width || 
                            1200;
                    height = svgElement.height?.baseVal?.value || 
                             parseFloat(svgElement.getAttribute('height')) || 
                             svgElement.getBoundingClientRect().height || 
                             800;
                }
                
                // Ensure minimum dimensions
                width = Math.max(width, 800);
                height = Math.max(height, 600);
                
                // Clean and prepare SVG
                let cleanSvg = svgData;
                
                // Ensure xmlns exists
                if (!cleanSvg.includes('xmlns=')) {
                    cleanSvg = cleanSvg.replace(/<svg([^>]*)>/i, '<svg$1 xmlns="http://www.w3.org/2000/svg">');
                }
                
                // Set explicit dimensions
                cleanSvg = cleanSvg.replace(/<svg([^>]*)>/i, (match, attrs) => {
                    // Remove existing width/height but keep viewBox
                    attrs = attrs.replace(/\s+(width|height)=["'][^"']*["']/gi, '');
                    if (!attrs.includes('viewBox')) {
                        return `<svg${attrs} width="${width}" height="${height}" viewBox="0 0 ${width} ${height}" xmlns="http://www.w3.org/2000/svg">`;
                    }
                    return `<svg${attrs} width="${width}" height="${height}" xmlns="http://www.w3.org/2000/svg">`;
                });
                
                // Create canvas
                const canvas = document.createElement('canvas');
                const scale = 2; // Higher quality
                canvas.width = width * scale;
                canvas.height = height * scale;
                const ctx = canvas.getContext('2d');
                
                // Fill white background
                ctx.fillStyle = 'white';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                
                // Scale context for better quality
                ctx.scale(scale, scale);
                
                // Create image
                const img = new Image();
                
                return new Promise((resolve, reject) => {
                    let attempt = 0;
                    const maxAttempts = 2;
                    
                    const tryLoad = (src) => {
                        attempt++;
                        
                        const timeout = setTimeout(() => {
                            if (attempt < maxAttempts) {
                                // Try alternative method
                                const altSrc = src.includes('blob:') 
                                    ? `data:image/svg+xml;base64,${btoa(unescape(encodeURIComponent(cleanSvg)))}`
                                    : URL.createObjectURL(new Blob([cleanSvg], { type: 'image/svg+xml;charset=utf-8' }));
                                tryLoad(altSrc);
                            } else {
                                reject(new Error('Failed to load SVG image'));
                            }
                        }, 5000);
                        
                        // Create new image for each attempt to avoid event handler conflicts
                        const newImg = attempt === 1 ? img : new Image();
                        
                        newImg.onload = () => {
                            clearTimeout(timeout);
                            try {
                                // Draw on canvas
                                ctx.drawImage(newImg, 0, 0, width, height);
                                
                                // Convert to PNG
                                canvas.toBlob((blob) => {
                                    if (blob) {
                                        const url = URL.createObjectURL(blob);
                                        const a = document.createElement('a');
                                        a.href = url;
                                        a.download = `${filename}.png`;
                                        document.body.appendChild(a);
                                        a.click();
                                        setTimeout(() => {
                                            document.body.removeChild(a);
                                            URL.revokeObjectURL(url);
                                            if (src.startsWith('blob:')) {
                                                URL.revokeObjectURL(src);
                                            }
                                        }, 100);
                                        resolve();
                                    } else {
                                        reject(new Error('Failed to create PNG blob'));
                                    }
                                }, 'image/png', 1.0);
                            } catch (error) {
                                clearTimeout(timeout);
                                console.error('Canvas error:', error);
                                reject(error);
                            }
                        };
                        
                        newImg.onerror = () => {
                            clearTimeout(timeout);
                            if (attempt < maxAttempts) {
                                // Try alternative
                                const altSrc = src.includes('blob:') 
                                    ? `data:image/svg+xml;base64,${btoa(unescape(encodeURIComponent(cleanSvg)))}`
                                    : URL.createObjectURL(new Blob([cleanSvg], { type: 'image/svg+xml;charset=utf-8' }));
                                tryLoad(altSrc);
                            } else {
                                reject(new Error('Failed to load SVG as image'));
                            }
                        };
                        
                        // Set source
                        newImg.src = src;
                    };
                    
                    // Start with Blob URL
                    const blobUrl = URL.createObjectURL(new Blob([cleanSvg], { type: 'image/svg+xml;charset=utf-8' }));
                    tryLoad(blobUrl);
                });
            } catch (error) {
                console.error('Download error:', error);
                alert('Error downloading diagram: ' + error.message);
                throw error;
            }
        }

        // Add message to conversation (UI only)
        function addMessage(text, sender) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}`;
            
            // Check for Mermaid diagrams in assistant messages
            if (sender === 'assistant') {
                const mermaidCodes = extractMermaidCode(text);
                console.log('Extracted Mermaid codes:', mermaidCodes);
                
                if (mermaidCodes.length > 0) {
                    // Remove Mermaid code blocks from text for chat display
                    let displayText = text.replace(/```mermaid\s*[\s\S]*?```/g, '').trim();
                    
                    // Display text in chat
                    if (displayText) {
                        messageDiv.textContent = displayText;
                    } else {
                        messageDiv.textContent = 'Diagram generated!';
                    }
                    
                    // Render diagram in left editor panel (use first diagram)
                    console.log('Rendering diagram with code:', mermaidCodes[0]);
                    renderMermaidDiagram(mermaidCodes[0]).then(success => {
                        if (success) {
                            console.log('Diagram rendered successfully');
                        } else {
                            console.error('Failed to render diagram');
                        }
                    }).catch(err => {
                        console.error('Error rendering diagram:', err);
                    });
                } else {
                    // No Mermaid code, just display text
                    console.log('No Mermaid code found in response');
                    messageDiv.textContent = text;
                }
            } else {
                // User message, just text
                messageDiv.textContent = text;
            }
            
            conversationDiv.appendChild(messageDiv);
            conversationDiv.scrollTop = conversationDiv.scrollHeight;
        }

        // Update status
        function updateStatus(text, className) {
            statusDiv.textContent = text;
            statusDiv.className = `status ${className}`;
        }

        // Detect silence and auto-stop recording
        function startSilenceDetection() {
            if (!microphoneStream || !isCalling) return;
            
            try {
                // Create audio context for silence detection
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                const source = audioContext.createMediaStreamSource(microphoneStream);
                source.connect(analyser);
                
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                lastSoundTime = Date.now();
                
                const checkSilence = () => {
                    if (!isCalling || !analyser) return;
                    
                    analyser.getByteFrequencyData(dataArray);
                    const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                    const normalized = average / 255;
                    
                    if (normalized > silenceThreshold) {
                        // Sound detected
                        lastSoundTime = Date.now();
                    } else {
                        // Check if silence for 2 seconds
                        const silenceDuration = Date.now() - lastSoundTime;
                        if (silenceDuration >= 2000 && mediaRecorder && mediaRecorder.state === 'recording') {
                            // 2 seconds of silence - stop recording
                            console.log('2 seconds of silence detected, stopping recording');
                            stopRecording();
                            return;
                        }
                    }
                    
                    if (isCalling) {
                        requestAnimationFrame(checkSilence);
                    }
                };
                
                checkSilence();
            } catch (error) {
                console.error('Error setting up silence detection:', error);
            }
        }

        // Start recording using existing stream
        function startRecording() {
            if (!microphoneStream) {
                console.error('No microphone stream available');
                return;
            }
            
            try {
                // Stop previous recorder if exists
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    mediaRecorder.stop();
                }
                
                // Clear any existing silence timer
                if (silenceTimer) {
                    clearTimeout(silenceTimer);
                    silenceTimer = null;
                }
                
                mediaRecorder = new MediaRecorder(microphoneStream, {
                    mimeType: 'audio/webm'
                });

                audioChunks = [];
                lastSoundTime = Date.now();

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    // Clean up audio context
                    if (audioContext) {
                        audioContext.close();
                        audioContext = null;
                        analyser = null;
                    }
                    
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    if (audioChunks.length > 0) {
                        await processAudio(audioBlob);
                    }
                };

                mediaRecorder.start();
                updateStatus('ðŸŽ¤ Ø£Ø³ØªÙ…Ø¹ Ø¥Ù„ÙŠÙƒ...', 'listening');
                
                // Start silence detection
                startSilenceDetection();
            } catch (error) {
                console.error('Error starting recording:', error);
                console.error('Error name:', error.name);
                console.error('Error message:', error.message);
                console.error('Error stack:', error.stack);
                updateStatus(`âŒ Recording Error: ${error.name} - ${error.message}`, 'error');
            }
        }

        // Stop recording
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
        }

        // Process audio: STT -> GPT -> TTS
        async function processAudio(audioBlob) {
            try {
                updateStatus('ðŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª...', 'processing');
                
                // Speech to Text
                const userText = await speechToText(audioBlob);
                addMessage(userText, 'user');

                updateStatus('ðŸ¤– ÙÙ‡Ø¯ ÙŠÙÙƒØ±...', 'processing');

                // Text processing (includes conversation history)
                let fahdResponse = await processText(userText);
                
                // Don't remove Mermaid code blocks, but clean other markdown
                // Keep mermaid code blocks intact
                fahdResponse = fahdResponse
                    .replace(/\*\*(?!mermaid)/g, '') // Remove ** but not in mermaid blocks
                    .replace(/\*(?!mermaid)/g, '') // Remove * but not in mermaid blocks
                    .trim();
                
                // Add both user message and assistant response to history
                conversationHistory.push({
                    role: 'user',
                    content: userText
                });
                conversationHistory.push({
                    role: 'assistant',
                    content: fahdResponse
                });
                
                // Display assistant's response in UI (diagram renders in left panel)
                addMessage(fahdResponse, 'assistant');

                updateStatus('Ready', 'idle');
                
                // If still recording, continue
                if (isCalling && microphoneStream) {
                    updateStatus('ðŸŽ¤ Recording...', 'listening');
                    startRecording();
                }
            } catch (error) {
                console.error('Processing error:', error);
                console.error('Error name:', error.name);
                console.error('Error message:', error.message);
                console.error('Error stack:', error.stack);
                updateStatus(`âŒ Processing Error: ${error.name} - ${error.message}`, 'error');
                addMessage(`Error: ${error.message}`, 'fahd');
                
                if (isCalling) {
                    setTimeout(() => {
                        startRecording();
                    }, 2000);
                }
            }
        }

        // Process text input
        async function processTextInput(userText) {
            if (!userText.trim()) return;
            
            addMessage(userText, 'user');
            textInput.value = '';
            textInput.disabled = true;
            sendButton.disabled = true;
            
            updateStatus('ðŸ¤– Processing...', 'processing');
            
            try {
                let response = await processText(userText);
                
                // Add to history
                conversationHistory.push({
                    role: 'user',
                    content: userText
                });
                conversationHistory.push({
                    role: 'assistant',
                    content: response
                });
                
                // Display response (with Mermaid rendering)
                addMessage(response, 'assistant');
                updateStatus('Ready', 'idle');
            } catch (error) {
                console.error('Processing error:', error);
                updateStatus(`âŒ Error: ${error.message}`, 'error');
                addMessage(`Error: ${error.message}`, 'assistant');
            } finally {
                textInput.disabled = false;
                sendButton.disabled = false;
                textInput.focus();
            }
        }

        // Text input handlers
        sendButton.addEventListener('click', () => {
            const text = textInput.value.trim();
            if (text) {
                processTextInput(text);
            }
        });

        textInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                const text = textInput.value.trim();
                if (text) {
                    processTextInput(text);
                }
            }
        });

        // Voice button handler
        voiceButton.addEventListener('click', async () => {
            if (!isCalling) {
                // Start voice recording
                updateStatus('ðŸŽ¤ Requesting microphone access...', 'processing');
                
                try {
                    microphoneStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    isCalling = true;
                    voiceButton.textContent = 'â¹ï¸ Stop Recording';
                    voiceButton.classList.add('recording');
                    updateStatus('ðŸŽ¤ Recording...', 'listening');
                    startRecording();
                } catch (error) {
                    console.error('Microphone error:', error);
                    updateStatus(`âŒ Microphone Error: ${error.message}`, 'error');
                }
            } else {
                // Stop voice recording
                isCalling = false;
                voiceButton.textContent = 'ðŸŽ¤ Record Voice';
                voiceButton.classList.remove('recording');
                stopRecording();
                
                if (microphoneStream) {
                    microphoneStream.getTracks().forEach(track => track.stop());
                    microphoneStream = null;
                }
                updateStatus('Ready', 'idle');
            }
        });


        // Initialize Mermaid
        mermaid.initialize({ startOnLoad: false, theme: 'default' });
    </script>
</body>
</html>